{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef34b23b-10dd-43cb-a425-ce7dd4858ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc38cdf-9841-4053-8189-8d5c42eb45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_black_borders(img:np.ndarray, thr=12, pad=0):\n",
    "    # thr parametresi, thresh değerini temsil ediyor. Arkaplan siyah\n",
    "    # renginde olduğu için 0'a çok yakın bir değer verdik.\n",
    "    # pad parametresi padding'i temsil ediyor. Görüntüyü, arkaplandan ayırt\n",
    "    # ettikten sonra sol, sağ, üst ve alt taraflarına boşluk bırakılıp\n",
    "    # bırakılmayacağına karar veriyor. Biz, varsayılan olarak 0 değeri \n",
    "    # girdiğimiz için 4 taraftan da tamamen ayırt edilmiş/kesilmiş tam bir\n",
    "    # görüntü elde etmek istediğimizi belirtiyoruz\n",
    "\n",
    "    # ilk olarak eğer görüntü renkli bir görüntüyse yani 3 kanallı ise\n",
    "    # bunun kontrolünü sağlıyoruz:\n",
    "\n",
    "    if img.ndim==3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "\n",
    "    # görüntüyü tek kanallı hale çevirdikten sonra ilk olarak\n",
    "    # arkaplandaki siyah piksellerden ayırt etmek için bir maske çıkarıyoruz\n",
    "\n",
    "    mask = (gray>thr).astype(np.uint8)*255\n",
    "    kernel = np.ones((5,5),dtype=np.uint8)\n",
    "\n",
    "    # yukarıda elimizde bir harita (mask) ve bir matris (filtre matrisi)\n",
    "    # var artık.\n",
    "\n",
    "    # siyah alandaki pikseller haricinde kalan kısımların haritasını\n",
    "    # elde ettikten sonra bu mevcut görüntüye siyah alanlardak iyice\n",
    "    # ayrılması için (küçük siyah detayların kaybolması için CLOSE yöntemini\n",
    "    # uyguluyoruz. Sonrasında elimizde temiz bir maske görüntüsü oluşuyor\n",
    "\n",
    "    \n",
    "    thresh = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Elimizdeki temiz maske görüntüsü içerisinden konturların listesini\n",
    "    # elde ediyoruz. Bu sayede, kenarları bir zincir gibi birleştirip\n",
    "    # tek bir görüntü elde etmeyi amaçlıyoruz.\n",
    "    \n",
    "    contour, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, \n",
    "                                  cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Elimize gelen contour değişkeni, görüntüdeki konturların tamamını\n",
    "    # bir liste olarak tutuyor. Bizim amacımız, bu listedeki en büyük\n",
    "    # kontur değerini saklayan değişkeni elde etmek\n",
    "\n",
    "    c = max(contour, key=cv2.contourArea)\n",
    "\n",
    "    # seçtiğimiz en büyük konturu (0,0) noktasından (x,y) tüm sütun (w) ve \n",
    "    # tüm satırları (h) elde edecek şekilde bir dikdörtgene dönüştürüyoruz\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "    # Kırpma işlemi esnasında görüntünün sınırlarının aşılmaması için\n",
    "    # görüntünün mevcut yükseklik ve genişlik bilgisini elde etmemiz gerekiyor\n",
    "    # biz görüntüyü, orijinal görüntü içerisinden crop yaparken sağ,sol,üst ve\n",
    "    # alt bölgelerden herhangi bir kayma veya aşınma olmasın istiyoruz.\n",
    "\n",
    "    H, W = img.shape[:2]\n",
    "    \n",
    "    # görüntünün yükseklik ve genişliğini elde ettikten sonra cropped\n",
    "    # işlemine geçiyoruz\n",
    "\n",
    "    # köşeleri tespit ediyoruz (4 köşe)\n",
    "\n",
    "    x1 = max(0, x - pad)\n",
    "    y1 = max(0, y - pad)\n",
    "    x2 = min(W, x + w + pad)\n",
    "    y2 = min(H, y + h + pad)\n",
    "\n",
    "    # 4 köşeyi de elde ettikten (taşma olmamasını sağladıktan) sonra\n",
    "    # ilgili görüntüyü, arkaplandan (orijinal görüntüden) koparıyoruz\n",
    "    \n",
    "    return img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e97fb5-38e1-401e-87c3-e264818c885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bgr_img = cv2.imread(\"./yeni1.png\")\n",
    "\n",
    "my_cropped_img = cropped_black_borders(my_bgr_img)\n",
    "\n",
    "cv2.imshow(\"Cropped Image\",my_cropped_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cba29a-674f-4fe1-8eb1-7acf234a8652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ybs4",
   "language": "python",
   "name": "env_ybs4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
